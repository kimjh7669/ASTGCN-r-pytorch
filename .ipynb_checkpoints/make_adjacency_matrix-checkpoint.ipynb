{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('C:/Users/Lim-LAB/Desktop/2021/현대 오토에버 교통예측/TimeInfo_5min_fill_Seoul_threshold/SEOUL_LINK_LIST.npy')\n",
    "ldata = pd.read_csv(\"C:/Users/Lim-LAB/Desktop/2021/현대 오토에버 교통예측/data/MOCT_LINK.csv\")\n",
    "\n",
    "cnt = 0\n",
    "car = {}\n",
    "for i in ldata.LINK_ID.unique():\n",
    "    car[i] = cnt\n",
    "    cnt += 1\n",
    "ldata['New_Link'] = [car[i] for i in ldata['LINK_ID'].values]\n",
    "\n",
    "node = {}\n",
    "n_cnt = 0\n",
    "for i in ldata.F_NODE.unique():\n",
    "    if node.get(i) == None:\n",
    "        node[i] = n_cnt\n",
    "        n_cnt += 1\n",
    "        \n",
    "        \n",
    "for i in ldata.T_NODE.unique():\n",
    "    if node.get(i) == None:\n",
    "        node[i] = n_cnt\n",
    "        n_cnt += 1\n",
    "\n",
    "mod_data = ldata[(ldata.LINK_ID / 10000000 >= 100) & (ldata.LINK_ID / 10000000 <= 124) ]\n",
    "mod_data = mod_data.reset_index(drop = True)\n",
    "mod_data = mod_data[(mod_data.ROAD_RANK == 101) | (mod_data.ROAD_RANK == 102)]\n",
    "mod_data =  mod_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "adjacent_matrix = [[0 for j in range(len(mod_data))] for i in range(len(mod_data))] \n",
    "\n",
    "cnt = 0\n",
    "car = {}\n",
    "for i in mod_data.LINK_ID.unique():\n",
    "    if car.get(i) == None:\n",
    "        car[i] = cnt\n",
    "        cnt += 1\n",
    "\n",
    "node = {}\n",
    "n_cnt = 0\n",
    "for i in mod_data.F_NODE.unique():\n",
    "    if node.get(i) == None:\n",
    "        node[i] = n_cnt\n",
    "        n_cnt += 1\n",
    "        \n",
    "for i in mod_data.T_NODE.unique():\n",
    "    if node.get(i) == None:\n",
    "        node[i] = n_cnt\n",
    "        n_cnt += 1\n",
    "\n",
    "mod_data['F'] = [node[i] for i in mod_data['F_NODE'].values]\n",
    "mod_data['T'] = [node[i] for i in mod_data['T_NODE'].values]\n",
    "\n",
    "f_list = list(mod_data['F'].values)\n",
    "\n",
    "t_list = list(mod_data['T'].values)\n",
    "\n",
    "link_list = list(mod_data['LINK_ID'].values)\n",
    "\n",
    "con_in = {}\n",
    "con_out = {}\n",
    "\n",
    "for i in range(len(f_list)):\n",
    "    main_link = link_list[i]\n",
    "    f_node = f_list[i]   # 링크의 시작 노드\n",
    "    \n",
    "    t_node = t_list[i]   # 링크의 끝 노드\n",
    "    \n",
    "    con_in[i] = []       # 링크로 들어오는 링크들 모음\n",
    "    con_out[i] = []      # 링크에서 나가는 링크들 모음\n",
    "    \n",
    "    con_in_num = t_list.count(f_node)     # 종료 노드들 중 f_node와 같은 링크들\n",
    "    con_out_num = f_list.count(t_node)    # 시작 노드들 중 t_node와 같은 링크들\n",
    "    \n",
    "    in_idx = -1    \n",
    "    \n",
    "    for j in range(con_out_num):\n",
    "        in_idx = f_list.index(t_node,in_idx+1)\n",
    "        if abs(main_link - link_list[in_idx]) == 100:    # 반대 방향으로 가는 노드들은 제거\n",
    "            continue\n",
    "        con_out[i].append(in_idx)\n",
    "        \n",
    "    out_idx = -1\n",
    "  \n",
    "    for j in range(con_in_num):\n",
    "        out_idx = t_list.index(f_node,out_idx+1)\n",
    "        if abs(main_link - link_list[out_idx]) == 100:    # 반대 방향으로 가는 노드들은 제거\n",
    "            continue\n",
    "        con_in[i].append(out_idx)\n",
    "   \n",
    "    \n",
    "\n",
    "for i in range(len(con_in)):\n",
    "    for j in range(len(con_in[i])):\n",
    "        adjacent_matrix[con_in[i][j]][i] = 1\n",
    "        \n",
    "        \n",
    "for i in range(len(con_out)):\n",
    "    for j in range(len(con_out[i])):\n",
    "        adjacent_matrix[i][con_out[i][j]] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "for i in range(len(con_in)):\n",
    "    adjacent_matrix[i][i] = 1\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacent_matrix = np.array(adjacent_matrix)\n",
    "np.save('./adjacency_matrix.npy', adjacent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('./adjacency_matrix.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "a = np.load('C:/Users/Lim-LAB/Desktop/Git/ASTGNN/data/PEMS04/PEMS04.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINK_LIST_PATH = 'C:/Users/Lim-LAB/Desktop/2021/현대 오토에버 교통예측/TimeInfo_5min_fill_Seoul/'\n",
    "TIME_DATA_PATH = 'C:/Users/Lim-LAB/Desktop/2021/현대 오토에버 교통예측/TimeInfo_5min_fill_Seoul_threshold/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = os.listdir(TIME_DATA_PATH)                  # npy파일 경로로 부터 파일들 리스트 불러오기\n",
    "link_file_name = 'SEOUL_LINK_LIST.npy'                  # 서울시 링크 리스트\n",
    "total_link_info_file_name = 'total.pickle'              # 앞 뒤 연결된 link matrix\n",
    "try:\n",
    "    file_list.remove(link_file_name)               # 만약 파일 경로에 LINK_LIST.npy를 포함하고 있으면 삭제.\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    file_list.remove(total_link_info_file_name)    # 만약 파일 경로에 LINK_LIST.npy를 포함하고 있으면 삭제.\n",
    "except:\n",
    "    pass\n",
    "\n",
    "file_list.sort()\n",
    "cur_file = pd.read_csv(TIME_DATA_PATH + file_list[0], header=0)\n",
    "cur_file_np = cur_file.to_numpy()\n",
    "new_np_file = cur_file_np[:, 289:577]\n",
    "\n",
    "for file_idx in range(1, len(file_list)):\n",
    "    cur_file = pd.read_csv(TIME_DATA_PATH + file_list[file_idx], header=0)\n",
    "    cur_file_np = cur_file.to_numpy()\n",
    "    \n",
    "    # print(cur_file_np[1:2])\n",
    "    # print(cur_file_np[2:3])\n",
    "    new_np_file = np.append(new_np_file, cur_file_np[:, 289:577], axis = 1)\n",
    "new_np_file = np.transpose(new_np_file, (1,0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tempfile import TemporaryFile\n",
    "outfile = TemporaryFile()\n",
    "np.savez(outfile, data = new_np_file)\n",
    "_ = outfile.seek(0)\n",
    "npzfile = np.load(outfile)\n",
    "sorted(npzfile.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lim-LAB\\\\Desktop\\\\Git\\\\ASTGCN-r-pytorch'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf929ba3211af63dc586dafc790d80eecfc9c4c3ae888cf6380685b6a965da52"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
